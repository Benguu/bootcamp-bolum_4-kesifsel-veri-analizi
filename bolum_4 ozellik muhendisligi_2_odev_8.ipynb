{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from matplotlib.mlab import PCA as mlabPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.decomposition import PCA\n",
    "from sqlalchemy import create_engine\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"whitegrid\")\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['figure.figsize'] = (8,5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>ENROLL</th>\n",
       "      <th>TOTAL_REVENUE</th>\n",
       "      <th>FEDERAL_REVENUE</th>\n",
       "      <th>STATE_REVENUE</th>\n",
       "      <th>LOCAL_REVENUE</th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>...</th>\n",
       "      <th>GRADES_4_G</th>\n",
       "      <th>GRADES_8_G</th>\n",
       "      <th>GRADES_12_G</th>\n",
       "      <th>GRADES_1_8_G</th>\n",
       "      <th>GRADES_9_12_G</th>\n",
       "      <th>GRADES_ALL_G</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1992_ALABAMA</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>1992</td>\n",
       "      <td>nan</td>\n",
       "      <td>2678885.000</td>\n",
       "      <td>304177.000</td>\n",
       "      <td>1659028.000</td>\n",
       "      <td>715680.000</td>\n",
       "      <td>2653798.000</td>\n",
       "      <td>1481703.000</td>\n",
       "      <td>...</td>\n",
       "      <td>57948.000</td>\n",
       "      <td>58025.000</td>\n",
       "      <td>41167.000</td>\n",
       "      <td>471564.000</td>\n",
       "      <td>196386.000</td>\n",
       "      <td>676174.000</td>\n",
       "      <td>208.328</td>\n",
       "      <td>252.188</td>\n",
       "      <td>207.964</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1992_ALASKA</td>\n",
       "      <td>ALASKA</td>\n",
       "      <td>1992</td>\n",
       "      <td>nan</td>\n",
       "      <td>1049591.000</td>\n",
       "      <td>106780.000</td>\n",
       "      <td>720711.000</td>\n",
       "      <td>222100.000</td>\n",
       "      <td>972488.000</td>\n",
       "      <td>498362.000</td>\n",
       "      <td>...</td>\n",
       "      <td>9748.000</td>\n",
       "      <td>8789.000</td>\n",
       "      <td>6714.000</td>\n",
       "      <td>79117.000</td>\n",
       "      <td>30847.000</td>\n",
       "      <td>112335.000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>258.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1992_ARIZONA</td>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1992</td>\n",
       "      <td>nan</td>\n",
       "      <td>3258079.000</td>\n",
       "      <td>297888.000</td>\n",
       "      <td>1369815.000</td>\n",
       "      <td>1590376.000</td>\n",
       "      <td>3401580.000</td>\n",
       "      <td>1435908.000</td>\n",
       "      <td>...</td>\n",
       "      <td>55433.000</td>\n",
       "      <td>49081.000</td>\n",
       "      <td>37410.000</td>\n",
       "      <td>437127.000</td>\n",
       "      <td>175210.000</td>\n",
       "      <td>614881.000</td>\n",
       "      <td>215.254</td>\n",
       "      <td>265.366</td>\n",
       "      <td>206.213</td>\n",
       "      <td>262.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1992_ARKANSAS</td>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1992</td>\n",
       "      <td>nan</td>\n",
       "      <td>1711959.000</td>\n",
       "      <td>178571.000</td>\n",
       "      <td>958785.000</td>\n",
       "      <td>574603.000</td>\n",
       "      <td>1743022.000</td>\n",
       "      <td>964323.000</td>\n",
       "      <td>...</td>\n",
       "      <td>34632.000</td>\n",
       "      <td>36011.000</td>\n",
       "      <td>27651.000</td>\n",
       "      <td>281338.000</td>\n",
       "      <td>123113.000</td>\n",
       "      <td>405259.000</td>\n",
       "      <td>210.206</td>\n",
       "      <td>256.312</td>\n",
       "      <td>208.634</td>\n",
       "      <td>264.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1992_CALIFORNIA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>1992</td>\n",
       "      <td>nan</td>\n",
       "      <td>26260025.000</td>\n",
       "      <td>2072470.000</td>\n",
       "      <td>16546514.000</td>\n",
       "      <td>7641041.000</td>\n",
       "      <td>27138832.000</td>\n",
       "      <td>14358922.000</td>\n",
       "      <td>...</td>\n",
       "      <td>418418.000</td>\n",
       "      <td>363296.000</td>\n",
       "      <td>270675.000</td>\n",
       "      <td>3286034.000</td>\n",
       "      <td>1372011.000</td>\n",
       "      <td>4717112.000</td>\n",
       "      <td>208.399</td>\n",
       "      <td>260.892</td>\n",
       "      <td>196.764</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRIMARY_KEY       STATE  YEAR  ENROLL  TOTAL_REVENUE  FEDERAL_REVENUE  \\\n",
       "0     1992_ALABAMA     ALABAMA  1992     nan    2678885.000       304177.000   \n",
       "1      1992_ALASKA      ALASKA  1992     nan    1049591.000       106780.000   \n",
       "2     1992_ARIZONA     ARIZONA  1992     nan    3258079.000       297888.000   \n",
       "3    1992_ARKANSAS    ARKANSAS  1992     nan    1711959.000       178571.000   \n",
       "4  1992_CALIFORNIA  CALIFORNIA  1992     nan   26260025.000      2072470.000   \n",
       "\n",
       "   STATE_REVENUE  LOCAL_REVENUE  TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "0    1659028.000     715680.000        2653798.000              1481703.000   \n",
       "1     720711.000     222100.000         972488.000               498362.000   \n",
       "2    1369815.000    1590376.000        3401580.000              1435908.000   \n",
       "3     958785.000     574603.000        1743022.000               964323.000   \n",
       "4   16546514.000    7641041.000       27138832.000             14358922.000   \n",
       "\n",
       "          ...           GRADES_4_G  GRADES_8_G  GRADES_12_G  GRADES_1_8_G  \\\n",
       "0         ...            57948.000   58025.000    41167.000    471564.000   \n",
       "1         ...             9748.000    8789.000     6714.000     79117.000   \n",
       "2         ...            55433.000   49081.000    37410.000    437127.000   \n",
       "3         ...            34632.000   36011.000    27651.000    281338.000   \n",
       "4         ...           418418.000  363296.000   270675.000   3286034.000   \n",
       "\n",
       "   GRADES_9_12_G  GRADES_ALL_G  AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  \\\n",
       "0     196386.000    676174.000           208.328           252.188   \n",
       "1      30847.000    112335.000               nan               nan   \n",
       "2     175210.000    614881.000           215.254           265.366   \n",
       "3     123113.000    405259.000           210.206           256.312   \n",
       "4    1372011.000   4717112.000           208.399           260.892   \n",
       "\n",
       "   AVG_READING_4_SCORE  AVG_READING_8_SCORE  \n",
       "0              207.964                  nan  \n",
       "1                  nan              258.860  \n",
       "2              206.213              262.170  \n",
       "3              208.634              264.620  \n",
       "4              196.764                  nan  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = pd.read_csv('C:\\\\Users\\\\PC\\\\Desktop\\\\states_all.csv')\n",
    "states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                     0.000\n",
       "STATE                           0.000\n",
       "YEAR                            0.000\n",
       "ENROLL                         17.627\n",
       "TOTAL_REVENUE                  14.209\n",
       "FEDERAL_REVENUE                14.209\n",
       "STATE_REVENUE                  14.209\n",
       "LOCAL_REVENUE                  14.209\n",
       "TOTAL_EXPENDITURE              14.209\n",
       "INSTRUCTION_EXPENDITURE        14.209\n",
       "SUPPORT_SERVICES_EXPENDITURE   14.209\n",
       "OTHER_EXPENDITURE              17.627\n",
       "CAPITAL_OUTLAY_EXPENDITURE     14.209\n",
       "GRADES_PK_G                    11.595\n",
       "GRADES_KG_G                     8.847\n",
       "GRADES_4_G                      8.780\n",
       "GRADES_8_G                      8.780\n",
       "GRADES_12_G                     8.780\n",
       "GRADES_1_8_G                    8.780\n",
       "GRADES_9_12_G                   8.780\n",
       "GRADES_ALL_G                   11.595\n",
       "AVG_MATH_4_SCORE               64.075\n",
       "AVG_MATH_8_SCORE               64.343\n",
       "AVG_READING_4_SCORE            64.276\n",
       "AVG_READING_8_SCORE            66.622\n",
       "dtype: float64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eksik değer var mı bakalım\n",
    "states.isnull().head()\n",
    "states.isnull().sum()*100/states.shape[0]   \n",
    "#oldukça fazla eksik değer var."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PRIMARY_KEY                    0.000\n",
       "STATE                          0.000\n",
       "YEAR                           0.000\n",
       "ENROLL                         3.418\n",
       "TOTAL_REVENUE                  0.000\n",
       "FEDERAL_REVENUE                0.000\n",
       "STATE_REVENUE                  0.000\n",
       "LOCAL_REVENUE                  0.000\n",
       "TOTAL_EXPENDITURE              0.000\n",
       "INSTRUCTION_EXPENDITURE        0.000\n",
       "SUPPORT_SERVICES_EXPENDITURE   0.000\n",
       "OTHER_EXPENDITURE              3.418\n",
       "CAPITAL_OUTLAY_EXPENDITURE     0.000\n",
       "GRADES_PK_G                    0.000\n",
       "GRADES_KG_G                    0.000\n",
       "GRADES_4_G                     0.000\n",
       "GRADES_8_G                     0.000\n",
       "GRADES_12_G                    0.000\n",
       "GRADES_1_8_G                   0.000\n",
       "GRADES_9_12_G                  0.000\n",
       "GRADES_ALL_G                   0.000\n",
       "AVG_MATH_4_SCORE               0.000\n",
       "AVG_MATH_8_SCORE               0.000\n",
       "AVG_READING_4_SCORE            0.000\n",
       "AVG_READING_8_SCORE            0.067\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eksik değerleri enterpolasyonla dolduralım\n",
    "statesint=states.interpolate()\n",
    "statesint.isnull().sum()*100/statesint.shape[0] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soru_1: Veri kümesindeki notların ağırlıklı ortalamasını içeren bir değişken oluşturun. \n",
    "Dördüncü sınıftaki öğrencilerin sayısı ile sekizinci sınıftaki öğrencilerin sayısı farklı. \n",
    "Bu yüzden ağırlıklı ortalamaya ihtiyacınız olacak!\n",
    "\n",
    "Matematik notları için ağırlıklı ortalamayı hesaplayalım."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      253.306\n",
       "1      252.181\n",
       "2      251.987\n",
       "3      253.711\n",
       "4      251.778\n",
       "5      252.030\n",
       "6      251.985\n",
       "7      252.949\n",
       "8      251.643\n",
       "9      251.750\n",
       "10     252.479\n",
       "11     251.605\n",
       "12     253.448\n",
       "13     253.388\n",
       "14     253.538\n",
       "15     253.061\n",
       "16     252.448\n",
       "17     253.362\n",
       "18     252.341\n",
       "19     252.524\n",
       "20     251.874\n",
       "21     252.262\n",
       "22     252.861\n",
       "23     252.801\n",
       "24     252.822\n",
       "25     252.876\n",
       "26     252.677\n",
       "27     252.920\n",
       "28     251.910\n",
       "29     251.765\n",
       "         ...  \n",
       "1462   252.281\n",
       "1463   252.281\n",
       "1464   252.281\n",
       "1465   252.281\n",
       "1466   252.281\n",
       "1467   252.281\n",
       "1468   252.281\n",
       "1469   252.281\n",
       "1470   252.281\n",
       "1471   252.281\n",
       "1472   252.281\n",
       "1473   252.281\n",
       "1474   252.281\n",
       "1475   252.281\n",
       "1476   252.281\n",
       "1477   252.281\n",
       "1478   252.281\n",
       "1479   252.281\n",
       "1480   252.281\n",
       "1481   252.281\n",
       "1482   252.281\n",
       "1483   252.281\n",
       "1484   252.281\n",
       "1485   252.281\n",
       "1486   252.281\n",
       "1487   252.281\n",
       "1488   252.281\n",
       "1489   252.281\n",
       "1490   252.281\n",
       "1491   252.281\n",
       "Name: weighted_average, Length: 1492, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statesint['weighted_average'] = (statesint['AVG_MATH_4_SCORE'].mean()*statesint['GRADES_4_G'] + statesint['AVG_MATH_8_SCORE'].mean()*\n",
    "statesint['GRADES_8_G'])/(statesint['GRADES_8_G'] + statesint['GRADES_4_G'])\n",
    "statesint['weighted_average']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soru_2:\n",
    "Yeni oluşturduğunuz değişken ile harcama çeşitlerinin korelasyonu nedir? \n",
    "Hangi harcama kaleminin korelasyonu diğerlerine göre fazladır?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>SUPPORT_SERVICES_EXPENDITURE</th>\n",
       "      <th>OTHER_EXPENDITURE</th>\n",
       "      <th>CAPITAL_OUTLAY_EXPENDITURE</th>\n",
       "      <th>GRADES_PK_G</th>\n",
       "      <th>GRADES_KG_G</th>\n",
       "      <th>GRADES_4_G</th>\n",
       "      <th>GRADES_8_G</th>\n",
       "      <th>GRADES_12_G</th>\n",
       "      <th>GRADES_1_8_G</th>\n",
       "      <th>GRADES_9_12_G</th>\n",
       "      <th>GRADES_ALL_G</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "      <th>weighted_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <td>0.992</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUPPORT_SERVICES_EXPENDITURE</th>\n",
       "      <td>0.994</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER_EXPENDITURE</th>\n",
       "      <td>0.949</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.956</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAPITAL_OUTLAY_EXPENDITURE</th>\n",
       "      <td>0.930</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.917</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_PK_G</th>\n",
       "      <td>0.691</td>\n",
       "      <td>0.653</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.744</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.784</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_KG_G</th>\n",
       "      <td>0.842</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.845</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.844</td>\n",
       "      <td>0.784</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.978</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_4_G</th>\n",
       "      <td>0.844</td>\n",
       "      <td>0.812</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.982</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_8_G</th>\n",
       "      <td>0.856</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.983</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_12_G</th>\n",
       "      <td>0.882</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.979</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.964</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_1_8_G</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.853</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.984</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_9_12_G</th>\n",
       "      <td>0.871</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.775</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.980</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_ALL_G</th>\n",
       "      <td>0.838</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.856</td>\n",
       "      <td>0.803</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <td>0.135</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.092</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.060</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <td>0.122</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.053</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.035</td>\n",
       "      <td>0.895</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <td>0.070</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>-0.106</td>\n",
       "      <td>-0.110</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.108</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.840</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "      <td>0.107</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.224</td>\n",
       "      <td>0.145</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.078</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.121</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "TOTAL_EXPENDITURE                         1.000                    0.992   \n",
       "INSTRUCTION_EXPENDITURE                   0.992                    1.000   \n",
       "SUPPORT_SERVICES_EXPENDITURE              0.994                    0.978   \n",
       "OTHER_EXPENDITURE                         0.949                    0.914   \n",
       "CAPITAL_OUTLAY_EXPENDITURE                0.930                    0.895   \n",
       "GRADES_PK_G                               0.691                    0.653   \n",
       "GRADES_KG_G                               0.842                    0.810   \n",
       "GRADES_4_G                                0.844                    0.812   \n",
       "GRADES_8_G                                0.856                    0.824   \n",
       "GRADES_12_G                               0.882                    0.849   \n",
       "GRADES_1_8_G                              0.846                    0.814   \n",
       "GRADES_9_12_G                             0.871                    0.840   \n",
       "GRADES_ALL_G                              0.838                    0.806   \n",
       "AVG_MATH_4_SCORE                          0.135                    0.132   \n",
       "AVG_MATH_8_SCORE                          0.122                    0.121   \n",
       "AVG_READING_4_SCORE                       0.070                    0.078   \n",
       "AVG_READING_8_SCORE                       0.107                    0.111   \n",
       "weighted_average                          0.078                    0.081   \n",
       "\n",
       "                              SUPPORT_SERVICES_EXPENDITURE  OTHER_EXPENDITURE  \\\n",
       "TOTAL_EXPENDITURE                                    0.994              0.949   \n",
       "INSTRUCTION_EXPENDITURE                              0.978              0.914   \n",
       "SUPPORT_SERVICES_EXPENDITURE                         1.000              0.956   \n",
       "OTHER_EXPENDITURE                                    0.956              1.000   \n",
       "CAPITAL_OUTLAY_EXPENDITURE                           0.915              0.917   \n",
       "GRADES_PK_G                                          0.690              0.717   \n",
       "GRADES_KG_G                                          0.845              0.895   \n",
       "GRADES_4_G                                           0.846              0.893   \n",
       "GRADES_8_G                                           0.858              0.899   \n",
       "GRADES_12_G                                          0.888              0.917   \n",
       "GRADES_1_8_G                                         0.848              0.894   \n",
       "GRADES_9_12_G                                        0.874              0.909   \n",
       "GRADES_ALL_G                                         0.838              0.879   \n",
       "AVG_MATH_4_SCORE                                     0.147              0.090   \n",
       "AVG_MATH_8_SCORE                                     0.133              0.085   \n",
       "AVG_READING_4_SCORE                                  0.078              0.027   \n",
       "AVG_READING_8_SCORE                                  0.115              0.098   \n",
       "weighted_average                                     0.081              0.077   \n",
       "\n",
       "                              CAPITAL_OUTLAY_EXPENDITURE  GRADES_PK_G  \\\n",
       "TOTAL_EXPENDITURE                                  0.930        0.691   \n",
       "INSTRUCTION_EXPENDITURE                            0.895        0.653   \n",
       "SUPPORT_SERVICES_EXPENDITURE                       0.915        0.690   \n",
       "OTHER_EXPENDITURE                                  0.917        0.717   \n",
       "CAPITAL_OUTLAY_EXPENDITURE                         1.000        0.744   \n",
       "GRADES_PK_G                                        0.744        1.000   \n",
       "GRADES_KG_G                                        0.844        0.784   \n",
       "GRADES_4_G                                         0.851        0.787   \n",
       "GRADES_8_G                                         0.861        0.787   \n",
       "GRADES_12_G                                        0.869        0.754   \n",
       "GRADES_1_8_G                                       0.853        0.789   \n",
       "GRADES_9_12_G                                      0.870        0.775   \n",
       "GRADES_ALL_G                                       0.856        0.803   \n",
       "AVG_MATH_4_SCORE                                   0.111        0.038   \n",
       "AVG_MATH_8_SCORE                                   0.083        0.036   \n",
       "AVG_READING_4_SCORE                                0.020       -0.025   \n",
       "AVG_READING_8_SCORE                                0.054        0.107   \n",
       "weighted_average                                   0.032        0.060   \n",
       "\n",
       "                              GRADES_KG_G  GRADES_4_G  GRADES_8_G  \\\n",
       "TOTAL_EXPENDITURE                   0.842       0.844       0.856   \n",
       "INSTRUCTION_EXPENDITURE             0.810       0.812       0.824   \n",
       "SUPPORT_SERVICES_EXPENDITURE        0.845       0.846       0.858   \n",
       "OTHER_EXPENDITURE                   0.895       0.893       0.899   \n",
       "CAPITAL_OUTLAY_EXPENDITURE          0.844       0.851       0.861   \n",
       "GRADES_PK_G                         0.784       0.787       0.787   \n",
       "GRADES_KG_G                         1.000       0.997       0.995   \n",
       "GRADES_4_G                          0.997       1.000       0.998   \n",
       "GRADES_8_G                          0.995       0.998       1.000   \n",
       "GRADES_12_G                         0.979       0.979       0.986   \n",
       "GRADES_1_8_G                        0.998       1.000       0.999   \n",
       "GRADES_9_12_G                       0.992       0.994       0.998   \n",
       "GRADES_ALL_G                        0.978       0.982       0.983   \n",
       "AVG_MATH_4_SCORE                   -0.092      -0.098      -0.084   \n",
       "AVG_MATH_8_SCORE                   -0.053      -0.058      -0.049   \n",
       "AVG_READING_4_SCORE                -0.106      -0.110      -0.103   \n",
       "AVG_READING_8_SCORE                 0.053       0.044       0.050   \n",
       "weighted_average                    0.088       0.090       0.117   \n",
       "\n",
       "                              GRADES_12_G  GRADES_1_8_G  GRADES_9_12_G  \\\n",
       "TOTAL_EXPENDITURE                   0.882         0.846          0.871   \n",
       "INSTRUCTION_EXPENDITURE             0.849         0.814          0.840   \n",
       "SUPPORT_SERVICES_EXPENDITURE        0.888         0.848          0.874   \n",
       "OTHER_EXPENDITURE                   0.917         0.894          0.909   \n",
       "CAPITAL_OUTLAY_EXPENDITURE          0.869         0.853          0.870   \n",
       "GRADES_PK_G                         0.754         0.789          0.775   \n",
       "GRADES_KG_G                         0.979         0.998          0.992   \n",
       "GRADES_4_G                          0.979         1.000          0.994   \n",
       "GRADES_8_G                          0.986         0.999          0.998   \n",
       "GRADES_12_G                         1.000         0.980          0.994   \n",
       "GRADES_1_8_G                        0.980         1.000          0.995   \n",
       "GRADES_9_12_G                       0.994         0.995          1.000   \n",
       "GRADES_ALL_G                        0.964         0.984          0.980   \n",
       "AVG_MATH_4_SCORE                   -0.028        -0.096         -0.060   \n",
       "AVG_MATH_8_SCORE                    0.000        -0.057         -0.029   \n",
       "AVG_READING_4_SCORE                -0.066        -0.108         -0.087   \n",
       "AVG_READING_8_SCORE                 0.079         0.046          0.061   \n",
       "weighted_average                    0.136         0.097          0.125   \n",
       "\n",
       "                              GRADES_ALL_G  AVG_MATH_4_SCORE  \\\n",
       "TOTAL_EXPENDITURE                    0.838             0.135   \n",
       "INSTRUCTION_EXPENDITURE              0.806             0.132   \n",
       "SUPPORT_SERVICES_EXPENDITURE         0.838             0.147   \n",
       "OTHER_EXPENDITURE                    0.879             0.090   \n",
       "CAPITAL_OUTLAY_EXPENDITURE           0.856             0.111   \n",
       "GRADES_PK_G                          0.803             0.038   \n",
       "GRADES_KG_G                          0.978            -0.092   \n",
       "GRADES_4_G                           0.982            -0.098   \n",
       "GRADES_8_G                           0.983            -0.084   \n",
       "GRADES_12_G                          0.964            -0.028   \n",
       "GRADES_1_8_G                         0.984            -0.096   \n",
       "GRADES_9_12_G                        0.980            -0.060   \n",
       "GRADES_ALL_G                         1.000            -0.069   \n",
       "AVG_MATH_4_SCORE                    -0.069             1.000   \n",
       "AVG_MATH_8_SCORE                    -0.035             0.895   \n",
       "AVG_READING_4_SCORE                 -0.088             0.790   \n",
       "AVG_READING_8_SCORE                  0.061             0.278   \n",
       "weighted_average                     0.093             0.011   \n",
       "\n",
       "                              AVG_MATH_8_SCORE  AVG_READING_4_SCORE  \\\n",
       "TOTAL_EXPENDITURE                        0.122                0.070   \n",
       "INSTRUCTION_EXPENDITURE                  0.121                0.078   \n",
       "SUPPORT_SERVICES_EXPENDITURE             0.133                0.078   \n",
       "OTHER_EXPENDITURE                        0.085                0.027   \n",
       "CAPITAL_OUTLAY_EXPENDITURE               0.083                0.020   \n",
       "GRADES_PK_G                              0.036               -0.025   \n",
       "GRADES_KG_G                             -0.053               -0.106   \n",
       "GRADES_4_G                              -0.058               -0.110   \n",
       "GRADES_8_G                              -0.049               -0.103   \n",
       "GRADES_12_G                              0.000               -0.066   \n",
       "GRADES_1_8_G                            -0.057               -0.108   \n",
       "GRADES_9_12_G                           -0.029               -0.087   \n",
       "GRADES_ALL_G                            -0.035               -0.088   \n",
       "AVG_MATH_4_SCORE                         0.895                0.790   \n",
       "AVG_MATH_8_SCORE                         1.000                0.840   \n",
       "AVG_READING_4_SCORE                      0.840                1.000   \n",
       "AVG_READING_8_SCORE                      0.224                0.145   \n",
       "weighted_average                         0.056               -0.000   \n",
       "\n",
       "                              AVG_READING_8_SCORE  weighted_average  \n",
       "TOTAL_EXPENDITURE                           0.107             0.078  \n",
       "INSTRUCTION_EXPENDITURE                     0.111             0.081  \n",
       "SUPPORT_SERVICES_EXPENDITURE                0.115             0.081  \n",
       "OTHER_EXPENDITURE                           0.098             0.077  \n",
       "CAPITAL_OUTLAY_EXPENDITURE                  0.054             0.032  \n",
       "GRADES_PK_G                                 0.107             0.060  \n",
       "GRADES_KG_G                                 0.053             0.088  \n",
       "GRADES_4_G                                  0.044             0.090  \n",
       "GRADES_8_G                                  0.050             0.117  \n",
       "GRADES_12_G                                 0.079             0.136  \n",
       "GRADES_1_8_G                                0.046             0.097  \n",
       "GRADES_9_12_G                               0.061             0.125  \n",
       "GRADES_ALL_G                                0.061             0.093  \n",
       "AVG_MATH_4_SCORE                            0.278             0.011  \n",
       "AVG_MATH_8_SCORE                            0.224             0.056  \n",
       "AVG_READING_4_SCORE                         0.145            -0.000  \n",
       "AVG_READING_8_SCORE                         1.000             0.121  \n",
       "weighted_average                            0.121             1.000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statesint = statesint.iloc[:,8:26]\n",
    "states_korelasyon = statesint.corr()\n",
    "states_korelasyon\n",
    "\n",
    "# ağırlıklı ortalama ile korelasyonları oldukça düşük.INSTRUCTION_EXPENDITURE ve SUPPORT_SERVICES_EXPENDITURE biraz daha yüksek."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Soru_3:\n",
    "Şimdi dört harcama kalemi için Temel Bileşenler Analizi (PCA) uygulayın! \n",
    "Toplam varyansın ne kadarı ilk bileşen tarafından açıklanabilmektedir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>SUPPORT_SERVICES_EXPENDITURE</th>\n",
       "      <th>OTHER_EXPENDITURE</th>\n",
       "      <th>CAPITAL_OUTLAY_EXPENDITURE</th>\n",
       "      <th>GRADES_PK_G</th>\n",
       "      <th>GRADES_KG_G</th>\n",
       "      <th>GRADES_4_G</th>\n",
       "      <th>GRADES_8_G</th>\n",
       "      <th>GRADES_12_G</th>\n",
       "      <th>GRADES_1_8_G</th>\n",
       "      <th>GRADES_9_12_G</th>\n",
       "      <th>GRADES_ALL_G</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "      <th>weighted_average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2833433.000</td>\n",
       "      <td>1564558.000</td>\n",
       "      <td>794146.000</td>\n",
       "      <td>237222.000</td>\n",
       "      <td>204207.000</td>\n",
       "      <td>8264.000</td>\n",
       "      <td>56598.000</td>\n",
       "      <td>57497.000</td>\n",
       "      <td>60004.000</td>\n",
       "      <td>39900.000</td>\n",
       "      <td>470775.000</td>\n",
       "      <td>198651.000</td>\n",
       "      <td>677690.000</td>\n",
       "      <td>225.288</td>\n",
       "      <td>274.960</td>\n",
       "      <td>221.119</td>\n",
       "      <td>261.722</td>\n",
       "      <td>253.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1126398.000</td>\n",
       "      <td>494917.000</td>\n",
       "      <td>433788.000</td>\n",
       "      <td>36291.000</td>\n",
       "      <td>135791.000</td>\n",
       "      <td>2787.000</td>\n",
       "      <td>10329.000</td>\n",
       "      <td>10156.000</td>\n",
       "      <td>9160.000</td>\n",
       "      <td>6975.000</td>\n",
       "      <td>80485.000</td>\n",
       "      <td>32347.000</td>\n",
       "      <td>115619.000</td>\n",
       "      <td>225.199</td>\n",
       "      <td>274.840</td>\n",
       "      <td>221.052</td>\n",
       "      <td>261.713</td>\n",
       "      <td>252.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>3623946.000</td>\n",
       "      <td>1578889.000</td>\n",
       "      <td>1000914.000</td>\n",
       "      <td>164083.000</td>\n",
       "      <td>680139.000</td>\n",
       "      <td>3164.000</td>\n",
       "      <td>57656.000</td>\n",
       "      <td>57701.000</td>\n",
       "      <td>53500.000</td>\n",
       "      <td>37614.000</td>\n",
       "      <td>461398.000</td>\n",
       "      <td>182737.000</td>\n",
       "      <td>647299.000</td>\n",
       "      <td>225.110</td>\n",
       "      <td>274.720</td>\n",
       "      <td>220.986</td>\n",
       "      <td>261.703</td>\n",
       "      <td>252.481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>1376067.000</td>\n",
       "      <td>782791.000</td>\n",
       "      <td>386526.000</td>\n",
       "      <td>68617.000</td>\n",
       "      <td>97824.000</td>\n",
       "      <td>1248.000</td>\n",
       "      <td>34337.000</td>\n",
       "      <td>34255.000</td>\n",
       "      <td>36471.000</td>\n",
       "      <td>27169.000</td>\n",
       "      <td>280280.000</td>\n",
       "      <td>125801.000</td>\n",
       "      <td>407329.000</td>\n",
       "      <td>225.021</td>\n",
       "      <td>274.600</td>\n",
       "      <td>220.919</td>\n",
       "      <td>261.694</td>\n",
       "      <td>253.964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>28110986.000</td>\n",
       "      <td>15281147.000</td>\n",
       "      <td>8914559.000</td>\n",
       "      <td>1608514.000</td>\n",
       "      <td>1944760.000</td>\n",
       "      <td>59954.000</td>\n",
       "      <td>444104.000</td>\n",
       "      <td>420233.000</td>\n",
       "      <td>380223.000</td>\n",
       "      <td>277271.000</td>\n",
       "      <td>3328627.000</td>\n",
       "      <td>1393530.000</td>\n",
       "      <td>4782111.000</td>\n",
       "      <td>224.932</td>\n",
       "      <td>274.480</td>\n",
       "      <td>220.852</td>\n",
       "      <td>261.684</td>\n",
       "      <td>252.219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  SUPPORT_SERVICES_EXPENDITURE  \\\n",
       "51        2833433.000              1564558.000                    794146.000   \n",
       "52        1126398.000               494917.000                    433788.000   \n",
       "53        3623946.000              1578889.000                   1000914.000   \n",
       "54        1376067.000               782791.000                    386526.000   \n",
       "55       28110986.000             15281147.000                   8914559.000   \n",
       "\n",
       "    OTHER_EXPENDITURE  CAPITAL_OUTLAY_EXPENDITURE  GRADES_PK_G  GRADES_KG_G  \\\n",
       "51         237222.000                  204207.000     8264.000    56598.000   \n",
       "52          36291.000                  135791.000     2787.000    10329.000   \n",
       "53         164083.000                  680139.000     3164.000    57656.000   \n",
       "54          68617.000                   97824.000     1248.000    34337.000   \n",
       "55        1608514.000                 1944760.000    59954.000   444104.000   \n",
       "\n",
       "    GRADES_4_G  GRADES_8_G  GRADES_12_G  GRADES_1_8_G  GRADES_9_12_G  \\\n",
       "51   57497.000   60004.000    39900.000    470775.000     198651.000   \n",
       "52   10156.000    9160.000     6975.000     80485.000      32347.000   \n",
       "53   57701.000   53500.000    37614.000    461398.000     182737.000   \n",
       "54   34255.000   36471.000    27169.000    280280.000     125801.000   \n",
       "55  420233.000  380223.000   277271.000   3328627.000    1393530.000   \n",
       "\n",
       "    GRADES_ALL_G  AVG_MATH_4_SCORE  AVG_MATH_8_SCORE  AVG_READING_4_SCORE  \\\n",
       "51    677690.000           225.288           274.960              221.119   \n",
       "52    115619.000           225.199           274.840              221.052   \n",
       "53    647299.000           225.110           274.720              220.986   \n",
       "54    407329.000           225.021           274.600              220.919   \n",
       "55   4782111.000           224.932           274.480              220.852   \n",
       "\n",
       "    AVG_READING_8_SCORE  weighted_average  \n",
       "51              261.722           253.749  \n",
       "52              261.713           252.185  \n",
       "53              261.703           252.481  \n",
       "54              261.694           253.964  \n",
       "55              261.684           252.219  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statesint=statesint.dropna()\n",
    "statesint.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kovaryans matrisi :\n",
      " [[ 1.00069444e+00  9.92400341e-01  9.94268645e-01  9.49358450e-01\n",
      "   9.30667624e-01  6.91106907e-01  8.46183165e-01  8.48506096e-01\n",
      "   8.58741233e-01  8.83836156e-01  8.50176027e-01  8.73899802e-01\n",
      "   8.41350278e-01  1.27549294e-01  1.17492336e-01  6.77875939e-02\n",
      "   1.07351299e-01  7.56670794e-02]\n",
      " [ 9.92400341e-01  1.00069444e+00  9.78608741e-01  9.14983491e-01\n",
      "   8.95022895e-01  6.52920623e-01  8.13750281e-01  8.16284992e-01\n",
      "   8.26274455e-01  8.50009736e-01  8.18063857e-01  8.41600685e-01\n",
      "   8.09117819e-01  1.24568754e-01  1.16711408e-01  7.63179265e-02\n",
      "   1.11613554e-01  7.79830148e-02]\n",
      " [ 9.94268645e-01  9.78608741e-01  1.00069444e+00  9.56331500e-01\n",
      "   9.15637939e-01  6.90058051e-01  8.49030812e-01  8.50353506e-01\n",
      "   8.60820897e-01  8.89726565e-01  8.51948562e-01  8.76707592e-01\n",
      "   8.41127081e-01  1.39345418e-01  1.29165125e-01  7.65238865e-02\n",
      "   1.14769092e-01  7.80428796e-02]\n",
      " [ 9.49358450e-01  9.14983491e-01  9.56331500e-01  1.00069444e+00\n",
      "   9.17388110e-01  7.17651518e-01  8.96117586e-01  8.93194723e-01\n",
      "   8.99926190e-01  9.17957369e-01  8.94343246e-01  9.10072246e-01\n",
      "   8.79572396e-01  9.01115510e-02  8.53021903e-02  2.70791176e-02\n",
      "   9.79034275e-02  7.67068836e-02]\n",
      " [ 9.30667624e-01  8.95022895e-01  9.15637939e-01  9.17388110e-01\n",
      "   1.00069444e+00  7.44717971e-01  8.51108837e-01  8.58343138e-01\n",
      "   8.66773731e-01  8.72421370e-01  8.59606210e-01  8.74885268e-01\n",
      "   8.61775955e-01  1.00227455e-01  7.58168608e-02  1.37185883e-02\n",
      "   5.37827302e-02  2.75553228e-02]\n",
      " [ 6.91106907e-01  6.52920623e-01  6.90058051e-01  7.17651518e-01\n",
      "   7.44717971e-01  1.00069444e+00  7.87634558e-01  7.90166335e-01\n",
      "   7.88357562e-01  7.54476300e-01  7.91537674e-01  7.76260266e-01\n",
      "   8.04664426e-01  3.15503899e-02  3.29088773e-02 -2.85968363e-02\n",
      "   1.07514472e-01  5.90632360e-02]\n",
      " [ 8.46183165e-01  8.13750281e-01  8.49030812e-01  8.96117586e-01\n",
      "   8.51108837e-01  7.87634558e-01  1.00069444e+00  9.98190853e-01\n",
      "   9.96132724e-01  9.80722752e-01  9.98328509e-01  9.92978035e-01\n",
      "   9.78544565e-01 -8.94249468e-02 -4.99871378e-02 -1.01904113e-01\n",
      "   5.25026838e-02  9.41000547e-02]\n",
      " [ 8.48506096e-01  8.16284992e-01  8.50353506e-01  8.93194723e-01\n",
      "   8.58343138e-01  7.90166335e-01  9.98190853e-01  1.00069444e+00\n",
      "   9.98761048e-01  9.80714494e-01  1.00044580e+00  9.94732362e-01\n",
      "   9.82696000e-01 -9.65518439e-02 -5.53186521e-02 -1.07115092e-01\n",
      "   4.30057401e-02  9.60196591e-02]\n",
      " [ 8.58741233e-01  8.26274455e-01  8.60820897e-01  8.99926190e-01\n",
      "   8.66773731e-01  7.88357562e-01  9.96132724e-01  9.98761048e-01\n",
      "   1.00069444e+00  9.86414952e-01  9.99537998e-01  9.98258107e-01\n",
      "   9.83602329e-01 -8.41472634e-02 -4.77291501e-02 -1.01777072e-01\n",
      "   4.96392410e-02  1.21513896e-01]\n",
      " [ 8.83836156e-01  8.50009736e-01  8.89726565e-01  9.17957369e-01\n",
      "   8.72421370e-01  7.54476300e-01  9.80722752e-01  9.80714494e-01\n",
      "   9.86414952e-01  1.00069444e+00  9.81652762e-01  9.94880410e-01\n",
      "   9.64611278e-01 -2.95080802e-02  5.66719977e-04 -6.63274363e-02\n",
      "   7.88093025e-02  1.38822465e-01]\n",
      " [ 8.50176027e-01  8.18063857e-01  8.51948562e-01  8.94343246e-01\n",
      "   8.59606210e-01  7.91537674e-01  9.98328509e-01  1.00044580e+00\n",
      "   9.99537998e-01  9.81652762e-01  1.00069444e+00  9.95653235e-01\n",
      "   9.84020908e-01 -9.41391602e-02 -5.38731436e-02 -1.05346417e-01\n",
      "   4.48272860e-02  1.02792576e-01]\n",
      " [ 8.73899802e-01  8.41600685e-01  8.76707592e-01  9.10072246e-01\n",
      "   8.74885268e-01  7.76260266e-01  9.92978035e-01  9.94732362e-01\n",
      "   9.98258107e-01  9.94880410e-01  9.95653235e-01  1.00069444e+00\n",
      "   9.80123403e-01 -6.12604599e-02 -2.81357095e-02 -8.67506348e-02\n",
      "   6.07859178e-02  1.28968651e-01]\n",
      " [ 8.41350278e-01  8.09117819e-01  8.41127081e-01  8.79572396e-01\n",
      "   8.61775955e-01  8.04664426e-01  9.78544565e-01  9.82696000e-01\n",
      "   9.83602329e-01  9.64611278e-01  9.84020908e-01  9.80123403e-01\n",
      "   1.00069444e+00 -6.86434578e-02 -3.27352366e-02 -8.65004630e-02\n",
      "   6.00381144e-02  9.75275888e-02]\n",
      " [ 1.27549294e-01  1.24568754e-01  1.39345418e-01  9.01115510e-02\n",
      "   1.00227455e-01  3.15503899e-02 -8.94249468e-02 -9.65518439e-02\n",
      "  -8.41472634e-02 -2.95080802e-02 -9.41391602e-02 -6.12604599e-02\n",
      "  -6.86434578e-02  1.00069444e+00  8.92800642e-01  7.88653502e-01\n",
      "   2.93020266e-01 -1.29599611e-02]\n",
      " [ 1.17492336e-01  1.16711408e-01  1.29165125e-01  8.53021903e-02\n",
      "   7.58168608e-02  3.29088773e-02 -4.99871378e-02 -5.53186521e-02\n",
      "  -4.77291501e-02  5.66719977e-04 -5.38731436e-02 -2.81357095e-02\n",
      "  -3.27352366e-02  8.92800642e-01  1.00069444e+00  8.37578010e-01\n",
      "   2.34065642e-01  4.05504588e-02]\n",
      " [ 6.77875939e-02  7.63179265e-02  7.65238865e-02  2.70791176e-02\n",
      "   1.37185883e-02 -2.85968363e-02 -1.01904113e-01 -1.07115092e-01\n",
      "  -1.01777072e-01 -6.63274363e-02 -1.05346417e-01 -8.67506348e-02\n",
      "  -8.65004630e-02  7.88653502e-01  8.37578010e-01  1.00069444e+00\n",
      "   1.57118731e-01 -2.27099712e-02]\n",
      " [ 1.07351299e-01  1.11613554e-01  1.14769092e-01  9.79034275e-02\n",
      "   5.37827302e-02  1.07514472e-01  5.25026838e-02  4.30057401e-02\n",
      "   4.96392410e-02  7.88093025e-02  4.48272860e-02  6.07859178e-02\n",
      "   6.00381144e-02  2.93020266e-01  2.34065642e-01  1.57118731e-01\n",
      "   1.00069444e+00  1.23412415e-01]\n",
      " [ 7.56670794e-02  7.79830148e-02  7.80428796e-02  7.67068836e-02\n",
      "   2.75553228e-02  5.90632360e-02  9.41000547e-02  9.60196591e-02\n",
      "   1.21513896e-01  1.38822465e-01  1.02792576e-01  1.28968651e-01\n",
      "   9.75275888e-02 -1.29599611e-02  4.05504588e-02 -2.27099712e-02\n",
      "   1.23412415e-01  1.00069444e+00]]\n"
     ]
    }
   ],
   "source": [
    "X = StandardScaler().fit_transform(statesint)\n",
    "\n",
    "Xt = X.T\n",
    "Cx = np.cov(Xt)\n",
    "print('Kovaryans matrisi :\\n', Cx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Özvektör 1: \n",
      "[-0.27398923 -0.26566472 -0.27391288 -0.27861789 -0.2710423  -0.23589165\n",
      " -0.28468506 -0.28522039 -0.28650954 -0.28651246 -0.28554272 -0.28766854\n",
      " -0.28275806 -0.00200593 -0.00696807  0.01046979 -0.02551809 -0.03099163]\n",
      "Özdeğer  1: 11.71444066226476\n",
      "----------------------------------------\n",
      "Özvektör 2: \n",
      "[ 0.08352435  0.08704318  0.08943831  0.05219115  0.04838791  0.0035234\n",
      " -0.06057536 -0.06458959 -0.0580296  -0.02493853 -0.06322908 -0.0442325\n",
      " -0.04907499  0.55977081  0.55848541  0.53128029  0.21118669  0.00830739]\n",
      "Özdeğer  2: 2.880593241781954\n",
      "----------------------------------------\n",
      "Özvektör 3: \n",
      "[-0.0549352  -0.05086583 -0.04877773 -0.04024137 -0.10341124  0.01255955\n",
      "  0.00906752  0.00592205  0.02490399  0.0400061   0.01129747  0.02997008\n",
      "  0.01187535 -0.03957155 -0.02532418 -0.11419037  0.5524529   0.80968439]\n",
      "Özdeğer  3: 1.086308673183777\n",
      "----------------------------------------\n",
      "Özvektör 4: \n",
      "[ 0.01190688  0.01324939  0.01250386  0.0103248   0.01352003  0.08141113\n",
      " -0.00796832 -0.01597529 -0.02904902 -0.0296642  -0.01926866 -0.03041086\n",
      " -0.00590713 -0.01242103 -0.13573944 -0.17165704  0.79116882 -0.56146411]\n",
      "Özdeğer  4: 0.8427724848621406\n",
      "----------------------------------------\n",
      "Özvektör 5: \n",
      "[ 0.38554865  0.44054248  0.36391677  0.20915053  0.20532503 -0.38593175\n",
      " -0.20445503 -0.20046636 -0.17475237 -0.09086372 -0.19804865 -0.13620386\n",
      " -0.21919094 -0.03534222 -0.16346928 -0.15145678  0.00466673  0.1116184 ]\n",
      "Özdeğer  5: 0.6158380673156142\n",
      "----------------------------------------\n",
      "Özvektör 6: \n",
      "[ 0.06748256  0.04219525  0.04019492 -0.0114639   0.22730692  0.83689684\n",
      " -0.16351782 -0.15082446 -0.14329845 -0.19522642 -0.14652199 -0.16430819\n",
      " -0.08227431  0.12954955 -0.05158902 -0.19395935 -0.1000073   0.09705064]\n",
      "Özdeğer  6: 0.3410355952110517\n",
      "----------------------------------------\n",
      "Özvektör 7: \n",
      "[-0.08150361 -0.15236879 -0.0620138   0.04735406  0.11719684 -0.20420375\n",
      "  0.02318463  0.01999128  0.03372098  0.09430134  0.01832034  0.05705206\n",
      "  0.01584357  0.51333979  0.27509958 -0.73941006 -0.08687975 -0.01835917]\n",
      "Özdeğer  7: 0.207600985736561\n",
      "----------------------------------------\n",
      "Özvektör 8: \n",
      "[-0.13744978 -0.30680875 -0.18999283  0.10058149  0.67403554 -0.16538102\n",
      " -0.03639936 -0.01385991  0.01488695 -0.02109437 -0.0082047   0.01138708\n",
      "  0.06086536  0.25412506 -0.47148073  0.24706794  0.03499795  0.06213705]\n",
      "Özdeğer  8: 0.10507173791518623\n",
      "----------------------------------------\n",
      "Özvektör 9: \n",
      "[ 0.01455957  0.07525234  0.12304142  0.08237634 -0.54668362  0.07038528\n",
      "  0.06654335  0.01476407  0.02663978  0.08532687  0.02019605  0.04132238\n",
      " -0.05924433  0.55621132 -0.57572485  0.06854612 -0.06762194  0.00446065]\n",
      "Özdeğer  9: 0.08540400885136035\n",
      "----------------------------------------\n",
      "Özvektör 10: \n",
      "[-0.11995402 -0.37759312  0.07886605  0.84898137 -0.14101687  0.06419629\n",
      "  0.03396615 -0.04442259 -0.06082475  0.02959751 -0.05036054 -0.05687698\n",
      " -0.21011047 -0.15561128  0.09933538  0.01809623  0.00251985 -0.00134325]\n",
      "Özdeğer  10: 0.06948608144139794\n",
      "----------------------------------------\n",
      "Özvektör 11: \n",
      "[-0.01538416  0.10646106 -0.08600044  0.24173657 -0.12645175 -0.08076996\n",
      " -0.06826651 -0.02681341 -0.06477692 -0.46869189 -0.00659315 -0.20027628\n",
      "  0.79216905  0.0391395  -0.00228987 -0.03287215 -0.00741108  0.02183981]\n",
      "Özdeğer  11: 0.028275558681588268\n",
      "----------------------------------------\n",
      "Özvektör 12: \n",
      "[-0.0126079   0.27972413 -0.32658762  0.10626312  0.04467193 -0.03033936\n",
      "  0.36340893  0.29488967  0.11925225 -0.55174928  0.26221716 -0.13542049\n",
      " -0.41370275  0.05799842  0.00316268 -0.02517139  0.00822963  0.02705708]\n",
      "Özdeğer  12: 0.020361220465101963\n",
      "----------------------------------------\n",
      "Özvektör 13: \n",
      "[ 1.22951587e-02  4.36248398e-01 -7.17383586e-01  2.33263576e-01\n",
      " -2.27148746e-02  4.93134376e-02 -8.02911258e-02 -1.78857415e-01\n",
      " -9.59259565e-02  3.90626481e-01 -1.53544024e-01  1.10690745e-01\n",
      "  3.19665428e-02 -6.05105418e-03 -3.91626935e-04  7.13443644e-03\n",
      " -7.61613477e-03 -1.77217251e-02]\n",
      "Özdeğer  13: 0.010041991332930234\n",
      "----------------------------------------\n",
      "Özvektör 14: \n",
      "[ 0.04220518 -0.04374593  0.05036926 -0.08790725  0.05515418 -0.00970941\n",
      "  0.77537024 -0.14834288 -0.48076773  0.16588528 -0.16987729 -0.24720895\n",
      "  0.10304095 -0.00160251 -0.00670548  0.00104957 -0.00633455  0.01915964]\n",
      "Özdeğer  14: 0.003377022221162983\n",
      "----------------------------------------\n",
      "Özvektör 15: \n",
      "[ 7.47655359e-02 -2.22900409e-02 -4.53320944e-02  2.56558638e-03\n",
      " -2.63043546e-03 -2.04795817e-03 -2.92901491e-01  6.64978635e-01\n",
      " -4.39235234e-01  2.63820448e-01  1.91283606e-01 -4.04898726e-01\n",
      "  1.37097629e-02  1.51505639e-02 -1.50194335e-02  1.27915467e-03\n",
      "  1.61398005e-04  1.21139110e-02]\n",
      "Özdeğer  15: 0.0010499853141861379\n",
      "----------------------------------------\n",
      "Özvektör 16: \n",
      "[-7.55257957e-01  3.66081536e-01  2.66845302e-01  4.64582690e-02\n",
      "  8.90730554e-02  1.05736001e-02 -2.77104157e-02  1.10335168e-01\n",
      " -3.18305392e-01 -5.01519955e-02 -2.70931424e-02  3.10648180e-01\n",
      " -9.54027103e-03 -6.60598829e-03  2.66929191e-03  3.14041290e-04\n",
      " -5.40434267e-04  2.31689651e-03]\n",
      "Özdeğer  16: 0.0004348483308786694\n",
      "----------------------------------------\n",
      "Özvektör 17: \n",
      "[-3.78302286e-01  2.03262692e-01  1.20739758e-01  9.97464981e-03\n",
      "  5.64509918e-02 -1.92263685e-03  2.64751646e-02 -1.40627177e-01\n",
      "  4.86957924e-01  2.69610856e-01  3.06356506e-02 -6.82923209e-01\n",
      "  8.82328916e-03 -2.42418680e-03  1.26849645e-03  5.38988422e-04\n",
      " -5.15510046e-04 -3.85317981e-04]\n",
      "Özdeğer  17: 0.00032860422923310464\n",
      "----------------------------------------\n",
      "Özvektör 18: \n",
      "[ 3.29869703e-03  1.79894441e-03 -3.53645147e-03 -3.16090115e-04\n",
      " -3.49920433e-03  1.49104761e-03  8.67358519e-02  4.82336465e-01\n",
      "  2.57117529e-01 -4.39483822e-02 -8.30922488e-01  3.07909366e-02\n",
      "  1.89757471e-02 -1.76599691e-03  4.28341474e-04  1.61950388e-03\n",
      " -2.77303085e-04 -7.75234692e-05]\n",
      "Özdeğer  18: 7.923086113694215e-05\n",
      "----------------------------------------\n",
      "Verikümesindeki toplam varyans yüzdesi Elle hesaplanan bileşen.\n",
      " [6.50350627e-01 1.59921901e-01 6.03086009e-02 4.67882018e-02\n",
      " 3.41894833e-02 1.89332738e-02 1.15253844e-02 5.83326789e-03\n",
      " 4.74137454e-03 3.85765893e-03 1.56977425e-03 1.13039392e-03\n",
      " 5.57501254e-04 1.87482150e-04 5.82920369e-05 2.41414757e-05\n",
      " 1.82431217e-05 4.39865988e-06]\n"
     ]
    }
   ],
   "source": [
    "eig_val_cov, eig_vec_cov = np.linalg.eig(Cx)\n",
    "\n",
    "# Inspecting the eigenvalues and eigenvectors.\n",
    "for i in range(len(eig_val_cov)):\n",
    "    eigvec_cov = eig_vec_cov[:, i].T\n",
    "    print('Özvektör {}: \\n{}'.format(i + 1, eigvec_cov))\n",
    "    print('Özdeğer  {}: {}'.format(i + 1, eig_val_cov[i]))\n",
    "    print(40 * '-')\n",
    "\n",
    "print(\n",
    "    'Verikümesindeki toplam varyans yüzdesi',\n",
    "    'Elle hesaplanan bileşen.\\n',\n",
    "    eig_val_cov / sum(eig_val_cov)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.17144407e+01 2.88059324e+00 1.08630867e+00 8.42772485e-01\n",
      " 6.15838067e-01 3.41035595e-01 2.07600986e-01 1.05071738e-01\n",
      " 8.54040089e-02 6.94860814e-02 2.82755587e-02 2.03612205e-02\n",
      " 1.00419913e-02 3.37702222e-03 1.04998531e-03 4.34848331e-04\n",
      " 3.28604229e-04 7.92308611e-05]\n"
     ]
    }
   ],
   "source": [
    "plt.plot(eig_val_cov)\n",
    "plt.show()\n",
    "\n",
    "print(eig_val_cov)\n",
    "\n",
    "# PCA ya 1 den büyük ilk 3 değişken var."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veri kümesindeki toplam varyans yüzdesi Elle hesaplanan bileşen.\n",
      " [0.65035063 0.1599219  0.0603086 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sklearn_pca = PCA(n_components=3)\n",
    "Y_sklearn = sklearn_pca.fit_transform(X)\n",
    "\n",
    "P = eig_vec_cov[:, 0]\n",
    "\n",
    "Y = P.T.dot(Xt)\n",
    "\n",
    "print(\n",
    "    'Veri kümesindeki toplam varyans yüzdesi',\n",
    "    'Elle hesaplanan bileşen.\\n',\n",
    "    sklearn_pca.explained_variance_ratio_\n",
    ")\n",
    "\n",
    "# Compare the sklearn solution to ours – a perfect match.\n",
    "plt.plot(Y_sklearn[:, 0], Y, 'o')\n",
    "plt.title('Çözümlerin Karşılaştırılması')\n",
    "plt.ylabel('Sklearn Bileşeni 1')\n",
    "plt.xlabel('Elle Hesaplanan Bileşen 1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toplam varyansın %65'i ilk değişken tarafından açıklanmaktadır."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soru_4\n",
    "Oluşturduğunuz genel not ortalaması ve ilk temel bileşen arasındaki korelasyon nedir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <th>SUPPORT_SERVICES_EXPENDITURE</th>\n",
       "      <th>OTHER_EXPENDITURE</th>\n",
       "      <th>CAPITAL_OUTLAY_EXPENDITURE</th>\n",
       "      <th>GRADES_PK_G</th>\n",
       "      <th>GRADES_KG_G</th>\n",
       "      <th>GRADES_4_G</th>\n",
       "      <th>GRADES_8_G</th>\n",
       "      <th>GRADES_12_G</th>\n",
       "      <th>GRADES_1_8_G</th>\n",
       "      <th>GRADES_9_12_G</th>\n",
       "      <th>GRADES_ALL_G</th>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "      <th>weighted_average</th>\n",
       "      <th>PCA1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TOTAL_EXPENDITURE</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.949</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INSTRUCTION_EXPENDITURE</th>\n",
       "      <td>0.992</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SUPPORT_SERVICES_EXPENDITURE</th>\n",
       "      <td>0.994</td>\n",
       "      <td>0.978</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OTHER_EXPENDITURE</th>\n",
       "      <td>0.949</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.956</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAPITAL_OUTLAY_EXPENDITURE</th>\n",
       "      <td>0.930</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.917</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_PK_G</th>\n",
       "      <td>0.691</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.717</td>\n",
       "      <td>0.744</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_KG_G</th>\n",
       "      <td>0.846</td>\n",
       "      <td>0.813</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.895</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.787</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.997</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.978</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_4_G</th>\n",
       "      <td>0.848</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.850</td>\n",
       "      <td>0.893</td>\n",
       "      <td>0.858</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.997</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.980</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.982</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_8_G</th>\n",
       "      <td>0.858</td>\n",
       "      <td>0.826</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.983</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_12_G</th>\n",
       "      <td>0.883</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.754</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.964</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_1_8_G</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.791</td>\n",
       "      <td>0.998</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.981</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.983</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_9_12_G</th>\n",
       "      <td>0.873</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.994</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.979</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GRADES_ALL_G</th>\n",
       "      <td>0.841</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.841</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.804</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.097</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG_MATH_4_SCORE</th>\n",
       "      <td>0.127</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.032</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>-0.061</td>\n",
       "      <td>-0.069</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.293</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG_MATH_8_SCORE</th>\n",
       "      <td>0.117</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.033</td>\n",
       "      <td>-0.050</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.048</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.054</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.892</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG_READING_4_SCORE</th>\n",
       "      <td>0.068</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.029</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.107</td>\n",
       "      <td>-0.102</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>-0.105</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.788</td>\n",
       "      <td>0.837</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG_READING_8_SCORE</th>\n",
       "      <td>0.107</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.079</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.293</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.157</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted_average</th>\n",
       "      <td>0.076</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.139</td>\n",
       "      <td>0.103</td>\n",
       "      <td>0.129</td>\n",
       "      <td>0.097</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.041</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.123</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCA1</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.995</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.891</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.079</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              TOTAL_EXPENDITURE  INSTRUCTION_EXPENDITURE  \\\n",
       "TOTAL_EXPENDITURE                         1.000                    0.992   \n",
       "INSTRUCTION_EXPENDITURE                   0.992                    1.000   \n",
       "SUPPORT_SERVICES_EXPENDITURE              0.994                    0.978   \n",
       "OTHER_EXPENDITURE                         0.949                    0.914   \n",
       "CAPITAL_OUTLAY_EXPENDITURE                0.930                    0.894   \n",
       "GRADES_PK_G                               0.691                    0.652   \n",
       "GRADES_KG_G                               0.846                    0.813   \n",
       "GRADES_4_G                                0.848                    0.816   \n",
       "GRADES_8_G                                0.858                    0.826   \n",
       "GRADES_12_G                               0.883                    0.849   \n",
       "GRADES_1_8_G                              0.850                    0.817   \n",
       "GRADES_9_12_G                             0.873                    0.841   \n",
       "GRADES_ALL_G                              0.841                    0.809   \n",
       "AVG_MATH_4_SCORE                          0.127                    0.124   \n",
       "AVG_MATH_8_SCORE                          0.117                    0.117   \n",
       "AVG_READING_4_SCORE                       0.068                    0.076   \n",
       "AVG_READING_8_SCORE                       0.107                    0.112   \n",
       "weighted_average                          0.076                    0.078   \n",
       "PCA1                                      0.995                    0.981   \n",
       "\n",
       "                              SUPPORT_SERVICES_EXPENDITURE  OTHER_EXPENDITURE  \\\n",
       "TOTAL_EXPENDITURE                                    0.994              0.949   \n",
       "INSTRUCTION_EXPENDITURE                              0.978              0.914   \n",
       "SUPPORT_SERVICES_EXPENDITURE                         1.000              0.956   \n",
       "OTHER_EXPENDITURE                                    0.956              1.000   \n",
       "CAPITAL_OUTLAY_EXPENDITURE                           0.915              0.917   \n",
       "GRADES_PK_G                                          0.690              0.717   \n",
       "GRADES_KG_G                                          0.848              0.895   \n",
       "GRADES_4_G                                           0.850              0.893   \n",
       "GRADES_8_G                                           0.860              0.899   \n",
       "GRADES_12_G                                          0.889              0.917   \n",
       "GRADES_1_8_G                                         0.851              0.894   \n",
       "GRADES_9_12_G                                        0.876              0.909   \n",
       "GRADES_ALL_G                                         0.841              0.879   \n",
       "AVG_MATH_4_SCORE                                     0.139              0.090   \n",
       "AVG_MATH_8_SCORE                                     0.129              0.085   \n",
       "AVG_READING_4_SCORE                                  0.076              0.027   \n",
       "AVG_READING_8_SCORE                                  0.115              0.098   \n",
       "weighted_average                                     0.078              0.077   \n",
       "PCA1                                                 0.995              0.973   \n",
       "\n",
       "                              CAPITAL_OUTLAY_EXPENDITURE  GRADES_PK_G  \\\n",
       "TOTAL_EXPENDITURE                                  0.930        0.691   \n",
       "INSTRUCTION_EXPENDITURE                            0.894        0.652   \n",
       "SUPPORT_SERVICES_EXPENDITURE                       0.915        0.690   \n",
       "OTHER_EXPENDITURE                                  0.917        0.717   \n",
       "CAPITAL_OUTLAY_EXPENDITURE                         1.000        0.744   \n",
       "GRADES_PK_G                                        0.744        1.000   \n",
       "GRADES_KG_G                                        0.851        0.787   \n",
       "GRADES_4_G                                         0.858        0.790   \n",
       "GRADES_8_G                                         0.866        0.788   \n",
       "GRADES_12_G                                        0.872        0.754   \n",
       "GRADES_1_8_G                                       0.859        0.791   \n",
       "GRADES_9_12_G                                      0.874        0.776   \n",
       "GRADES_ALL_G                                       0.861        0.804   \n",
       "AVG_MATH_4_SCORE                                   0.100        0.032   \n",
       "AVG_MATH_8_SCORE                                   0.076        0.033   \n",
       "AVG_READING_4_SCORE                                0.014       -0.029   \n",
       "AVG_READING_8_SCORE                                0.054        0.107   \n",
       "weighted_average                                   0.028        0.059   \n",
       "PCA1                                               0.924        0.698   \n",
       "\n",
       "                              GRADES_KG_G  GRADES_4_G  GRADES_8_G  \\\n",
       "TOTAL_EXPENDITURE                   0.846       0.848       0.858   \n",
       "INSTRUCTION_EXPENDITURE             0.813       0.816       0.826   \n",
       "SUPPORT_SERVICES_EXPENDITURE        0.848       0.850       0.860   \n",
       "OTHER_EXPENDITURE                   0.895       0.893       0.899   \n",
       "CAPITAL_OUTLAY_EXPENDITURE          0.851       0.858       0.866   \n",
       "GRADES_PK_G                         0.787       0.790       0.788   \n",
       "GRADES_KG_G                         1.000       0.997       0.995   \n",
       "GRADES_4_G                          0.997       1.000       0.998   \n",
       "GRADES_8_G                          0.995       0.998       1.000   \n",
       "GRADES_12_G                         0.980       0.980       0.986   \n",
       "GRADES_1_8_G                        0.998       1.000       0.999   \n",
       "GRADES_9_12_G                       0.992       0.994       0.998   \n",
       "GRADES_ALL_G                        0.978       0.982       0.983   \n",
       "AVG_MATH_4_SCORE                   -0.089      -0.096      -0.084   \n",
       "AVG_MATH_8_SCORE                   -0.050      -0.055      -0.048   \n",
       "AVG_READING_4_SCORE                -0.102      -0.107      -0.102   \n",
       "AVG_READING_8_SCORE                 0.052       0.043       0.050   \n",
       "weighted_average                    0.094       0.096       0.121   \n",
       "PCA1                                0.867       0.867       0.876   \n",
       "\n",
       "                              GRADES_12_G  GRADES_1_8_G  GRADES_9_12_G  \\\n",
       "TOTAL_EXPENDITURE                   0.883         0.850          0.873   \n",
       "INSTRUCTION_EXPENDITURE             0.849         0.817          0.841   \n",
       "SUPPORT_SERVICES_EXPENDITURE        0.889         0.851          0.876   \n",
       "OTHER_EXPENDITURE                   0.917         0.894          0.909   \n",
       "CAPITAL_OUTLAY_EXPENDITURE          0.872         0.859          0.874   \n",
       "GRADES_PK_G                         0.754         0.791          0.776   \n",
       "GRADES_KG_G                         0.980         0.998          0.992   \n",
       "GRADES_4_G                          0.980         1.000          0.994   \n",
       "GRADES_8_G                          0.986         0.999          0.998   \n",
       "GRADES_12_G                         1.000         0.981          0.994   \n",
       "GRADES_1_8_G                        0.981         1.000          0.995   \n",
       "GRADES_9_12_G                       0.994         0.995          1.000   \n",
       "GRADES_ALL_G                        0.964         0.983          0.979   \n",
       "AVG_MATH_4_SCORE                   -0.029        -0.094         -0.061   \n",
       "AVG_MATH_8_SCORE                    0.001        -0.054         -0.028   \n",
       "AVG_READING_4_SCORE                -0.066        -0.105         -0.087   \n",
       "AVG_READING_8_SCORE                 0.079         0.045          0.061   \n",
       "weighted_average                    0.139         0.103          0.129   \n",
       "PCA1                                0.900         0.869          0.891   \n",
       "\n",
       "                              GRADES_ALL_G  AVG_MATH_4_SCORE  \\\n",
       "TOTAL_EXPENDITURE                    0.841             0.127   \n",
       "INSTRUCTION_EXPENDITURE              0.809             0.124   \n",
       "SUPPORT_SERVICES_EXPENDITURE         0.841             0.139   \n",
       "OTHER_EXPENDITURE                    0.879             0.090   \n",
       "CAPITAL_OUTLAY_EXPENDITURE           0.861             0.100   \n",
       "GRADES_PK_G                          0.804             0.032   \n",
       "GRADES_KG_G                          0.978            -0.089   \n",
       "GRADES_4_G                           0.982            -0.096   \n",
       "GRADES_8_G                           0.983            -0.084   \n",
       "GRADES_12_G                          0.964            -0.029   \n",
       "GRADES_1_8_G                         0.983            -0.094   \n",
       "GRADES_9_12_G                        0.979            -0.061   \n",
       "GRADES_ALL_G                         1.000            -0.069   \n",
       "AVG_MATH_4_SCORE                    -0.069             1.000   \n",
       "AVG_MATH_8_SCORE                    -0.033             0.892   \n",
       "AVG_READING_4_SCORE                 -0.086             0.788   \n",
       "AVG_READING_8_SCORE                  0.060             0.293   \n",
       "weighted_average                     0.097            -0.013   \n",
       "PCA1                                 0.857             0.120   \n",
       "\n",
       "                              AVG_MATH_8_SCORE  AVG_READING_4_SCORE  \\\n",
       "TOTAL_EXPENDITURE                        0.117                0.068   \n",
       "INSTRUCTION_EXPENDITURE                  0.117                0.076   \n",
       "SUPPORT_SERVICES_EXPENDITURE             0.129                0.076   \n",
       "OTHER_EXPENDITURE                        0.085                0.027   \n",
       "CAPITAL_OUTLAY_EXPENDITURE               0.076                0.014   \n",
       "GRADES_PK_G                              0.033               -0.029   \n",
       "GRADES_KG_G                             -0.050               -0.102   \n",
       "GRADES_4_G                              -0.055               -0.107   \n",
       "GRADES_8_G                              -0.048               -0.102   \n",
       "GRADES_12_G                              0.001               -0.066   \n",
       "GRADES_1_8_G                            -0.054               -0.105   \n",
       "GRADES_9_12_G                           -0.028               -0.087   \n",
       "GRADES_ALL_G                            -0.033               -0.086   \n",
       "AVG_MATH_4_SCORE                         0.892                0.788   \n",
       "AVG_MATH_8_SCORE                         1.000                0.837   \n",
       "AVG_READING_4_SCORE                      0.837                1.000   \n",
       "AVG_READING_8_SCORE                      0.234                0.157   \n",
       "weighted_average                         0.041               -0.023   \n",
       "PCA1                                     0.112                0.061   \n",
       "\n",
       "                              AVG_READING_8_SCORE  weighted_average  PCA1  \n",
       "TOTAL_EXPENDITURE                           0.107             0.076 0.995  \n",
       "INSTRUCTION_EXPENDITURE                     0.112             0.078 0.981  \n",
       "SUPPORT_SERVICES_EXPENDITURE                0.115             0.078 0.995  \n",
       "OTHER_EXPENDITURE                           0.098             0.077 0.973  \n",
       "CAPITAL_OUTLAY_EXPENDITURE                  0.054             0.028 0.924  \n",
       "GRADES_PK_G                                 0.107             0.059 0.698  \n",
       "GRADES_KG_G                                 0.052             0.094 0.867  \n",
       "GRADES_4_G                                  0.043             0.096 0.867  \n",
       "GRADES_8_G                                  0.050             0.121 0.876  \n",
       "GRADES_12_G                                 0.079             0.139 0.900  \n",
       "GRADES_1_8_G                                0.045             0.103 0.869  \n",
       "GRADES_9_12_G                               0.061             0.129 0.891  \n",
       "GRADES_ALL_G                                0.060             0.097 0.857  \n",
       "AVG_MATH_4_SCORE                            0.293            -0.013 0.120  \n",
       "AVG_MATH_8_SCORE                            0.234             0.041 0.112  \n",
       "AVG_READING_4_SCORE                         0.157            -0.023 0.061  \n",
       "AVG_READING_8_SCORE                         1.000             0.123 0.110  \n",
       "weighted_average                            0.123             1.000 0.079  \n",
       "PCA1                                        0.110             0.079 1.000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states_3 = statesint[['INSTRUCTION_EXPENDITURE', 'SUPPORT_SERVICES_EXPENDITURE', 'OTHER_EXPENDITURE' ]]\n",
    "scaled_data = preprocessing.scale(states_3)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(scaled_data)\n",
    "pca_data = pca.transform(scaled_data)\n",
    "pca_data.T[0]\n",
    "\n",
    "statesint['PCA1'] = pca_data.T[0]\n",
    "statesint.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soru_5:\n",
    "İlk ve ikinci temel değişken, varyansın çoğunu açıkladığı için bu değişkenleri tercih edebiliriz."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
